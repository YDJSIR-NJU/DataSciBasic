# 数据科学大作业报告划分与分工表

## 0.0 格式相关内容

**余东骏**

## 0.1 摘要与关键词

## 1. 研究背景

> **余东骏**

## 2. 项目的代码实现

### 2.1 爬虫与数据获取部分

> **丛进、余东骏**

### 2.1 数据筛选与统计学分析部分

**余东骏**

#### 筛选后的文件目录

文件按照`stage`划分，其中`stage` 1 - 5按照《抗击疫情的中国行动》划分，`stage0`为2019年12月8日发现首例新冠病例到2019年12月26日，`stage6`是2020年6月21日至2020年12月20日。

##### stage内文件目录结构

```bash
│  COVkeywords-Stage<No>-.json # 人工筛选后的疫情相关关键词
│  COVkeywords-Stage<No>.json  # 未经筛选的疫情关键词
│  keywords-Stage<No>.json	   # 从荔枝新闻中获取的原始结果
│  ratioByDate.png			   # 该阶段内每日疫情相关重点微博占比
│  SaveTest.png				   # 疫情相关度分布拟合结果图1
│  SaveTest_Fit.png			   # 疫情相关度分布拟合结果图2
│  stageCOVWeibo.json		   # 该阶段内疫情相关重点微博（按时间先后排序）
│  stageCOVWeiboByImportance.json	# 该阶段内疫情相关重点微博（按疫情相关度排序）
│  stageInfo.json			   # 该阶段基础信息
│
├─YYYY-MM-DD-
├─YYYY-MM-DD-
├─YYYY-MM-DD-
├─YYYY-MM-DD-
...
└─YYYY-MM-DD-
```

##### 每个日期内文件目录结构

```bash
YYYY-MM-DD 
| jstvRAW.csv # 疫情相关关键词检索得到的荔枝新闻原始数据
| <YYYY-MM-DD->keywords.json # 荔枝新闻正文提取出来的关键词及其乘以100以后的TextRank权值
| <YYYY-MM-DD->wordcloud.html # 由荔枝新闻生成的词云图
| <YYYY-MM-DD->blog-Scored.json # 每篇微博都有一个疫情相关度
| <YYYY-MM-DD->blog-COV.json # 筛选后的新冠疫情相关微博
| <YYYY-MM-DD->blogInfo.json # 当日博客相关基础信息
| <YYYY-MM-DD->weiboEmotion.png # 基于心态词典的当日疫情相关微博重点评论情感分析生成的雷达图
└─<YYYY-MM-DD->weiboEmotion.csv # 基于心态词典的当日疫情相关微博重点评论情感分析原始数据
```



### 2.3 心态词典情感分析部分

**丛进**



### 2.4 机器学习部分

**许礼孟**



## 3. 分阶段结果分析

每个人对自己所使用的方法展开论述，结构与`数据分析和代码实现` 部分颇为类似，但此部分需要的合作与对话内容颇多，大家也可以更好地建言献策。

> 前置：数据分析和代码实现

### stage0

**余东骏**

### stage1

**丛进**

### stage2

**余东骏**

### stage3

**余东骏**

### stage4

**丛进**

### stage5

**余东骏**

### stage6

**余东骏**

## 4. 总结

**余东骏**

## 5. 参考资料

**余东骏**

## 6. 研究感想

**余东骏**

## 7. 附录

**余东骏**

## * 报告汇总

传了一轮大家都觉得没问题后YDJSIR进行最终汇总，复核后再无问题之后最后提交。

> 数据分析和代码实现

## * PPT制作与汇报

再行商议